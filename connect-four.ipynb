{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2021 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see 'LICENCE.md' for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLUMNS = 7\n",
    "COLUMN_HEIGHT = 6\n",
    "FOUR = 4\n",
    "\n",
    "# Board can be initiatilized with `board = np.zeros((NUM_COLUMNS, COLUMN_HEIGHT), dtype=np.byte)`\n",
    "# Notez Bien: Connect 4 \"columns\" are actually NumPy \"rows\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_moves(board):\n",
    "    \"\"\"Returns columns where a disc may be played\"\"\"\n",
    "    return [n for n in range(NUM_COLUMNS) if board[n, COLUMN_HEIGHT - 1] == 0]\n",
    "\n",
    "\n",
    "def play(board, column, player):\n",
    "    \"\"\"Updates `board` as `player` drops a disc in `column`\"\"\"\n",
    "    (index,) = next((i for i, v in np.ndenumerate(board[column]) if v == 0))\n",
    "    board[column, index] = player\n",
    "\n",
    "\n",
    "def take_back(board, column):\n",
    "    \"\"\"Updates `board` removing top disc from `column`\"\"\"\n",
    "    (index,) = [i for i, v in np.ndenumerate(board[column]) if v != 0][-1]\n",
    "    board[column, index] = 0\n",
    "\n",
    "\n",
    "def four_in_a_row(board, player):\n",
    "    \"\"\"Checks if `player` has a 4-piece line\"\"\"\n",
    "    return (\n",
    "        any(\n",
    "            all(board[c, r] == player)\n",
    "            for c in range(NUM_COLUMNS)\n",
    "            for r in (list(range(n, n + FOUR)) for n in range(COLUMN_HEIGHT - FOUR + 1))\n",
    "        )\n",
    "        or any(\n",
    "            all(board[c, r] == player)\n",
    "            for r in range(COLUMN_HEIGHT)\n",
    "            for c in (list(range(n, n + FOUR)) for n in range(NUM_COLUMNS - FOUR + 1))\n",
    "        )\n",
    "        or any(\n",
    "            np.all(board[diag] == player)\n",
    "            for diag in (\n",
    "                (range(ro, ro + FOUR), range(co, co + FOUR))\n",
    "                for ro in range(0, NUM_COLUMNS - FOUR + 1)\n",
    "                for co in range(0, COLUMN_HEIGHT - FOUR + 1)\n",
    "            )\n",
    "        )\n",
    "        or any(\n",
    "            np.all(board[diag] == player)\n",
    "            for diag in (\n",
    "                (range(ro, ro + FOUR), range(co + FOUR - 1, co - 1, -1))\n",
    "                for ro in range(0, NUM_COLUMNS - FOUR + 1)\n",
    "                for co in range(0, COLUMN_HEIGHT - FOUR + 1)\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montecarlo Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mc(board, player):\n",
    "    p = -player\n",
    "    while valid_moves(board):\n",
    "        p = -p\n",
    "        c = np.random.choice(valid_moves(board))\n",
    "        play(board, c, p)\n",
    "        if four_in_a_row(board, p):\n",
    "            return p\n",
    "    return 0\n",
    "\n",
    "\n",
    "def montecarlo(board, player):\n",
    "    montecarlo_samples = 100\n",
    "    cnt = Counter(_mc(np.copy(board), player) for _ in range(montecarlo_samples))\n",
    "    return (cnt[1] - cnt[-1]) / montecarlo_samples\n",
    "\n",
    "\n",
    "def eval_board(board, player):\n",
    "    if four_in_a_row(board, 1):\n",
    "        # Alice won\n",
    "        return 1\n",
    "    elif four_in_a_row(board, -1):\n",
    "        # Bob won\n",
    "        return -1\n",
    "    else:\n",
    "        # Not terminal, let's simulate...\n",
    "        return montecarlo(board, player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 -1 -1 -1  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = board = np.zeros((NUM_COLUMNS, COLUMN_HEIGHT), dtype=np.byte)\n",
    "play(board, 3, 1)\n",
    "play(board, 0, -1)\n",
    "play(board, 4, 1)\n",
    "play(board, 0, -1)\n",
    "play(board, 5, 1)\n",
    "play(board, 0, -1)\n",
    "play(board, 0, -1)\n",
    "print(board)\n",
    "eval_board(board, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "class state_dict:\n",
    "\n",
    "  def __init__(self):\n",
    "    self.dict = {}\n",
    "\n",
    "  def check(board: np.ndarray, player: int):\n",
    "    # TODO: check dict\n",
    "    return\n",
    "\n",
    "  def store(board: np.ndarray, player: int):\n",
    "    # TODO: store state\n",
    "    return\n",
    "  \n",
    "\n",
    "def who_won(board: np.ndarray) -> int:\n",
    "  if four_in_a_row(board, 1):\n",
    "    return 1\n",
    "  elif four_in_a_row(board, -1):\n",
    "    return -1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\n",
    "def compute_heuristic(board: np.ndarray) -> float:\n",
    "  \"\"\"Value between -1 and 1, computed by counting possible winning configurations for each player\"\"\"\n",
    "\n",
    "  if who_won(board):  # game has ended\n",
    "    return who_won(board)\n",
    "\n",
    "  total_count = NUM_COLUMNS * (COLUMN_HEIGHT - FOUR + 1) \\\n",
    "                + COLUMN_HEIGHT * (NUM_COLUMNS - FOUR + 1) \\\n",
    "                + 2 * (NUM_COLUMNS - FOUR + 1) * (COLUMN_HEIGHT - FOUR + 1)\n",
    "  board1 = np.copy(board) + (board == 0)\n",
    "  board2 = np.copy(board) + (board == 0)\n",
    "\n",
    "  return (\n",
    "    sum(\n",
    "      all(board1[c, r] == 1) - all(board2[c, r] == -1)\n",
    "      for c in range(NUM_COLUMNS)\n",
    "      for r in (list(range(n, n + FOUR)) for n in range(COLUMN_HEIGHT - FOUR + 1))\n",
    "    )\n",
    "    + sum(\n",
    "      all(board[c, r] == 1) - all(board2[c, r] == -1)\n",
    "      for r in range(COLUMN_HEIGHT)\n",
    "      for c in (list(range(n, n + FOUR)) for n in range(NUM_COLUMNS - FOUR + 1))\n",
    "    )\n",
    "    + sum(\n",
    "      np.all(board[diag] == 1).astype(np.byte) - np.all(board2[diag] == -1)\n",
    "      for diag in (\n",
    "        (range(ro, ro + FOUR), range(co, co + FOUR))\n",
    "        for ro in range(0, NUM_COLUMNS - FOUR + 1)\n",
    "        for co in range(0, COLUMN_HEIGHT - FOUR + 1)\n",
    "      )\n",
    "    )\n",
    "    + sum(\n",
    "      np.all(board[diag] == 1).astype(np.byte) - np.all(board2[diag] == -1)\n",
    "      for diag in (\n",
    "        (range(ro, ro + FOUR), range(co + FOUR - 1, co - 1, -1))\n",
    "        for ro in range(0, NUM_COLUMNS - FOUR + 1)\n",
    "        for co in range(0, COLUMN_HEIGHT - FOUR + 1)\n",
    "      )\n",
    "    )\n",
    "  ) / total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DEPTH = 4\n",
    "\n",
    "def minmax(board: np.ndarray, player: int, depth: int) -> Tuple[int, float]:\n",
    "  \"\"\"Pick best move for player at each turn looking depth moves ahead\"\"\"\n",
    "  if depth == 0:\n",
    "    return None, compute_heuristic(board)\n",
    "  else:\n",
    "    consider_moves = []  # contains list of tuples (move, heuristic)\n",
    "    for move in valid_moves(board):\n",
    "      play(board, move, player)  # make move\n",
    "      winner = who_won(board)\n",
    "      if winner == player:  # player wins\n",
    "        heuristic = compute_heuristic(board)\n",
    "        take_back(board, move)\n",
    "        return move, heuristic\n",
    "      if winner == -player:  # player looses\n",
    "        take_back(board, move)\n",
    "        continue\n",
    "      else:\n",
    "        _, heuristic = minmax(board, -player, depth-1)\n",
    "        consider_moves.append((move, heuristic))\n",
    "        take_back(board, move)\n",
    "    if len(consider_moves) == 0:  # every valid move results in defeat\n",
    "      return None, -player\n",
    "    return max(consider_moves, key=lambda item: player * item[1])  # return best move for player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_LENGTH = 10\n",
    "EXPLOITATION_BONUS = 1.2\n",
    "NUM_SIMULATIONS = 10\n",
    "HEURISTIC_OFFSET = 0  # ensure that nodes can get picked even if they don't win with default policy\n",
    "\n",
    "def simulate_random(board: np.ndarray, player: int) -> int:\n",
    "  \"\"\"Simulate random moves, return winner\"\"\"\n",
    "  board = np.copy(board)\n",
    "  while valid_moves(board) and not who_won(board):\n",
    "    move = np.random.choice(valid_moves(board))\n",
    "    play(board, move, player)\n",
    "    player = -player\n",
    "  return who_won(board)\n",
    "\n",
    "\n",
    "def run_default_policy(board: np.ndarray, player_max: int, player_turn: int, n: int=NUM_SIMULATIONS) -> float:\n",
    "  \"\"\"Run n random simulations and return win percentage for player_max plus offset\"\"\"\n",
    "  num_wins = 0\n",
    "  for _ in range(NUM_SIMULATIONS):\n",
    "    if simulate_random(board, player_turn) == player_max:\n",
    "      num_wins += 1\n",
    "  return (num_wins + HEURISTIC_OFFSET) / (NUM_SIMULATIONS + HEURISTIC_OFFSET)\n",
    "\n",
    "\n",
    "def expand_node(board: np.ndarray, player: int, moves: List[int]) -> List[Tuple[List[int], float]]:\n",
    "  \"\"\"Get original board and player along with list of moves leading to node we are expanding.\"\"\"\n",
    "  player_max = player\n",
    "  player_turn = player\n",
    "  board = board.copy()\n",
    "  children = []\n",
    "  for move in moves:  # set board to state of current node\n",
    "    play(board, move, player_turn)\n",
    "    player_turn = -player_turn\n",
    "  if who_won(board):  # don't expand terminal nodes\n",
    "    return [(moves, run_default_policy(board, player_max, player_turn))]\n",
    "  for move in valid_moves(board):  # for each child\n",
    "    play(board, move, player_turn)\n",
    "    if who_won(board) == -player_max:  # opponent wins\n",
    "      return []  # discard this subtree as opponent can always win\n",
    "    elif who_won(board) == player_max:  # player wins\n",
    "      return [(moves + [move], run_default_policy(board, player_max, -player_turn))]  # this move results in victory\n",
    "    child = (moves + [move], run_default_policy(board, player_max, -player_turn))\n",
    "    children.append(child)\n",
    "    take_back(board, move)\n",
    "  return children\n",
    "  \n",
    "\n",
    "def montecarlo_sample(nodes: List[Tuple[List[int], float]]) -> List[Tuple[List[int], float]]:\n",
    "  \"\"\"Pick node to expand and remove from list\"\"\"\n",
    "  compute_weight = lambda node: node[1] * EXPLOITATION_BONUS ** len(node[0])  # heuristic * EXPLOITATION_BONUS ** depth\n",
    "  weights = [compute_weight(node) for node in nodes]  # compute weights\n",
    "  p = [w / sum(weights) for w in weights]  # normalize\n",
    "  idx_choice = np.random.choice(len(nodes), p=p)\n",
    "  return nodes.pop(idx_choice)  # remove node from list and return it\n",
    "\n",
    "\n",
    "def montecarlo_search(board: np.ndarray, player: int, search_length: int=SEARCH_LENGTH) -> int:\n",
    "  nodes = [([], run_default_policy(board, player, player))]  # contains list of tuples (list of moves, heuristic)\n",
    "  for _ in range(search_length):\n",
    "    if len(nodes) == 0:  # usually occurs when no options left\n",
    "      return np.random.choice(valid_moves(board))\n",
    "    next_node = montecarlo_sample(nodes)\n",
    "    nodes += expand_node(board, player, next_node[0])\n",
    "  return (montecarlo_sample(nodes)[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_human(board: np.ndarray, player: int):\n",
    "  print(board)\n",
    "  move = -1\n",
    "  while move not in valid_moves(board):\n",
    "    move = int(input())\n",
    "  play(board, move, player)\n",
    "\n",
    "\n",
    "def play_minmax(board: np.ndarray, player: int):\n",
    "  move, prediction = minmax(board, -1, MAX_DEPTH)\n",
    "  if prediction == -player:  # game is already lost\n",
    "    move = np.random.choice(valid_moves(board))\n",
    "  play(board, move, player)\n",
    "\n",
    "\n",
    "def play_montecarlo(board: np.ndarray, player: int):\n",
    "  move = montecarlo_search(board, player)\n",
    "  play(board, move, player)\n",
    "\n",
    "\n",
    "def play_game():\n",
    "  \"\"\"Play vs the computer\"\"\"\n",
    "  board = np.zeros((NUM_COLUMNS, COLUMN_HEIGHT), dtype=np.byte)\n",
    "  while len(valid_moves(board))>0 and not who_won(board):\n",
    "    play_montecarlo(board, 1)\n",
    "    play_human(board, -1)\n",
    "  print(f'Player {who_won(board)} won!')\n",
    "  print(board)\n",
    "\n",
    "play_game()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe44fef87f92f48a3a32707d0df204585f471652bc0ce87358a3ce712bc24db0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
